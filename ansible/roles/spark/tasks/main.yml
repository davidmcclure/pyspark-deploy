---

- name: Set worker count
  set_fact:
    spark_worker_count: '{{ groups["workers"] | length }}'

- name: Get worker facts
  become: no
  register: worker
  run_once: yes
  local_action:
    module: ec2_instance_facts
    instance_ids: '{{ tf_first_worker_id }}'
    region: '{{ tf_aws_region }}'

- name: Set worker CPU count
  set_fact:
    spark_worker_cpu_count: '{{ worker.instances[0].cpu_options.core_count}}'

- name: apt-get update
  apt:
    update_cache: yes

# TODO: Pre-bake base image?
- name: Install Docker
  include_role:
    name: geerlingguy.docker

- name: Install docker-py
  include_role:
    name: geerlingguy.pip
  vars:
    pip_install_packages:
      - name: docker

- name: Create config directory
  file:
    path: '{{ spark_config_dir }}'
    state: directory

- name: Render Spark config
  template:
    src: '{{ item }}.j2'
    dest: '{{ spark_config_dir }}/{{ item }}'
  with_items:
    - spark-defaults.conf
    - spark-env.sh

- name: Render Docker bash script
  template:
    src: docker-bash.sh.j2
    dest: /home/{{ ansible_user }}/docker-bash.sh
    owner: '{{ ansible_user }}'
    mode: u+x

- name: Automatically connect to container on login
  lineinfile:
    path: /home/{{ ansible_user }}/.bashrc
    line: source ./docker-bash.sh

- name: Start master
  include_tasks: start_container.yml
  when: '"master" in group_names'
  vars:
    command: spark-class org.apache.spark.deploy.master.Master

- name: Start workers
  include_tasks: start_container.yml
  when: '"workers" in group_names'
  vars:
    command: >
      spark-class org.apache.spark.deploy.worker.Worker
      {{ spark_master_url }}
