---

- name: Wait for SSH connection
  wait_for_connection:

- name: Gather facts, after SSH
  setup:

# TODO: Move to AMI?
- name: Install docker-py
  pip:
    name: docker

- name: Create directories
  file:
    path: '{{ item }}'
    state: directory
  with_items:
    - '{{ spark_config_dir }}'
    - '{{ spark_data_root }}'

- name: Render Spark config
  template:
    src: '{{ item }}.j2'
    dest: '{{ spark_config_dir }}/{{ item }}'
  with_items:
    - spark-defaults.conf
    - spark-env.sh
    - log4j.properties

- name: Render Docker bash script
  template:
    src: docker-bash.sh.j2
    dest: /home/{{ ansible_user }}/docker-bash.sh
    owner: '{{ ansible_user }}'
    mode: u+x

- name: Automatically connect to container on login
  lineinfile:
    path: /home/{{ ansible_user }}/.bashrc
    line: source ./docker-bash.sh

- name: Login to AWS ECR
  shell: >
    $(aws ecr get-login --no-include-email
    --region {{ spark_ecr_region }})
  when: spark_ecr_login|bool
  environment:
    AWS_ACCESS_KEY_ID: '{{ aws_access_key_id }}'
    AWS_SECRET_ACCESS_KEY: '{{ aws_secret_access_key }}'

- name: Start master
  include_tasks: start_container.yml
  when: '"master" in group_names'
  vars:
    name: spark-master
    runtime: '{{ tf_master_docker_runtime }}'
    command: spark-class org.apache.spark.deploy.master.Master

- name: Start workers
  include_tasks: start_container.yml
  when: '"workers" in group_names'
  vars:
    name: spark-worker
    runtime: '{{ tf_worker_docker_runtime }}'
    command: >
      spark-class org.apache.spark.deploy.worker.Worker
      {{ spark_master_url }}
